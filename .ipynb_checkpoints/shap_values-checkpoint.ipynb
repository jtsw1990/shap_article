{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable ML: A peek into the black box through SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rework in progress\n",
    "\n",
    "The insurance industry has always been more conservative when it comes to modelling, and with good reason. The financial and social impact of a wrongly predicted say, fraud detection model denying a policyholder’s entitlement to a claim is huge, and could lead to anti-discrimination allegations. Compare that to the impact of a wrongly predicted song recommendation pushed from your favourite music player’s machine learning algorithm. \n",
    "\n",
    "As a result of this, a considerable level of transparency is required to explain the basis of decisions made by models to various stakeholders. Apart from the professional standards, one could refer to the [information note](https://actuaries.logicaldoc.cloud/download-ticket?ticketId=85c37260-4721-4864-ae2b-24e043bef8ce) provide by the Data Analytics Working Group on the guidelines when considering the level of transparency required.\n",
    "\n",
    "While GLMs offer this transparency and unambiguity of model results, it limits the model choice which may sometimes cause am issue when the underlying interactions are more complex, and we need a more complicated black-box model to accomodate this.\n",
    "\n",
    "There are some tools and techniques available to explain individual (local) deicsions of a black box model in case of a need to manually review/ debug the model, and this might be sufficient to address explainable decisions for some applications. \n",
    "\n",
    "This article will go through SHAP, which is one of the aforementioned techniques available. Although this article will make use of the Python implementaion, there is also a R wrapper for the shap package called [shapper](https://github.com/ModelOriented/shapper), or ml3 which works with [DALEX](https://mlr-org.com/docs/mlr3-loves-dalex/). For more information on how to get started with DALEX, check out [Jacky Poon's top 10 R packages for data analysis](https://institute-and-faculty-of-actuaries.github.io/mlr-blog/post/topten-r-packages/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this from your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python code shown this snippet can be run from your browser through this [link](https://mybinder.org/v2/gh/jtsw1990/shap_article/HEAD).\n",
    "\n",
    "Note that some loading time is to be expected, particularly when performing gridsearch and cross-validation for the machine learning models. However, the binder does not require the reader to download the dataset, or any other dependencies to run the models. Furthermore, the reader is encouraged to play around with the code and look at how SHAP explains the different predictions, as well as explore other graphs that the SHAP package has to offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example uses [Python3](https://www.python.org/downloads/release/python-379/) and the main packages that we will be using are listed below:\n",
    "\n",
    "- [Shap](https://pypi.org/project/shap/) for model validation\n",
    "- [Matplotlib](https://pypi.org/project/matplotlib/) for visualisation as shap graphs uses it as a backend\n",
    "- [Pandas](https://pypi.org/project/pandas/) and [Numpy](https://pypi.org/project/numpy/) for general data manipulation\n",
    "- [Sci-kit learn's](https://pypi.org/project/scikit-learn/) pipeline framework and machine learning algorithms\n",
    "\n",
    "Note that the sklearn pipeline is the main backbone of the process here out of convenience but any other workflow/ preprocessing framework would work just as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8460d662c010>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shap\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.ioff()\n",
    "%load_ext hierarchymagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing, Preprocessing, Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this article includes some policyholder information as follows: \n",
    "\n",
    "- **age**: Policyholder age (_integer_)\n",
    "- **sex**: Gender of the policyholder (_string_)\n",
    "- **bmi**: Body mass index (_float_)\n",
    "- **children**: Number of children/ dependents of policyholder (_integer_)\n",
    "- **smoker**: Smoking state of policyholder (_string_)\n",
    "- **region**: Residential area of the policyholder in the US (_string_)\n",
    "\n",
    "As well as a **claims cost** response column. The data can be downloaded from the github repository [here](https://github.com/sharmaroshan/Insurance-Claim-Prediction).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although all the usual steps in the modelling process are involved here, this article will mainly focus on using the SHAP package and interpreting the model predictions. With that in mind, the rest of this section will not be covered in detail, but includes:\n",
    "- Importing the data\n",
    "- Splitting the dataset into training and testing sets\n",
    "- Creating a \"preprocessor\" step to one-hot-encode categorical features\n",
    "- Building a sklearn pipeline with the preprocessing and a GBM Regressor model\n",
    "- Performing gridsearch and cross-validation for the GBM model to get the \"best\" set of hyperparameters\n",
    "- 2 very brief/high-level checks to ensure that:\n",
    "    - Nothing has gone terribly wrong in the model and we are in the ballpark in terms of predictions\n",
    "    - We have not grossly overfitted on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from GitHub repository\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/sharmaroshan/Insurance-Claim-Prediction/master/insurance.csv\")\n",
    "\n",
    "# Get column names for independent and response variables\n",
    "rating_factors_col = list(df.columns[:-1])\n",
    "claims_col = df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting up the categorical columns and numerical columns\n",
    "# This is to differentiate the preprocessing steps applied later in the pipeline\n",
    "\n",
    "num_features = list(df[rating_factors_col].select_dtypes(include=[\"int64\", \"float64\"]).columns)\n",
    "cat_features = [col for col in rating_factors_col if col not in num_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our dataset into training and testing sets. Using 20/80 split here.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df[rating_factors_col],\n",
    "            df[claims_col],\n",
    "            test_size=0.2,\n",
    "            random_state=123\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessor step\n",
    "# This ignores numerical columns but applies OHE to categorical features\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"numerical\", \"passthrough\", num_features),\n",
    "        (\"categorical\", OneHotEncoder(sparse=False, handle_unknown=\"ignore\"), cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some wrangling done to get OHE feature names\n",
    "# Note that XXXX method can be used as well\n",
    "\n",
    "ohe_categories = preprocessor.fit(X_train).named_transformers_[\"categorical\"].categories_\n",
    "ohe_categories_concat = [f\"{col}__{val}\" for col, vals in zip(cat_features, ohe_categories) for val in vals]\n",
    "rating_factors_encoded = num_features + ohe_categories_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of hyperparameters to be optimised\n",
    "# Create a sklearn Pipeline object which takes in the preprocessor step as well as a GBM object\n",
    "\n",
    "param_grid = {\n",
    "    \"model__learning_rate\": [0.01, 0.1],\n",
    "    \"model__max_depth\": [2, 3, 4],\n",
    "    \"model__min_samples_leaf\": [1, 3, 5],\n",
    "    \"model__min_samples_split\": [2, 4],\n",
    "    \"model__n_estimators\": [100, 200]\n",
    "}\n",
    "\n",
    "gbm_model = Pipeline([(\"preprocessor\", preprocessor), (\"model\", GradientBoostingRegressor())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling: Gradient Boosted Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a gridsearch-cross validation object\n",
    "# This takes in our previously created gbm pipeline and grid of hyperparameters to be tested\n",
    "# Using a standard 5 part CV split with MSE as a score as we are doing a regression exercise\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    gbm_model, \n",
    "    param_grid=param_grid, \n",
    "    n_jobs=-1, \n",
    "    cv=5, \n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the gridsearch, set the hyperparameters to the set which gave us the lowest MSE\n",
    "# Fit the optimised model on our training data set and get test set predictions\n",
    "\n",
    "_gs = gs.fit(X_train, y_train)\n",
    "\n",
    "gbm_model.set_params(**gs.best_params_)\n",
    "gbm_model.fit(X_train, y_train)\n",
    "gbm_pred = gbm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reasonableness checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function created to create a mutliple bar chart comparing actual claims\n",
    "# costs vs predicted claims costs split by deciles\n",
    "\n",
    "def plot_avepp(df, expected, actual):\n",
    "    avepp = df.assign(\n",
    "        model_bands=pd.qcut(df[expected], 10, labels=np.arange(10) + 1),\n",
    "    ).groupby(\"model_bands\")[[expected, actual]].agg(\"sum\").reset_index()\n",
    "    n = avepp[\"model_bands\"].max()\n",
    "    width = 0.35\n",
    "    ax = plt.subplot(111)\n",
    "    pred_fig = ax.bar(np.arange(n) + width, avepp[expected], width)\n",
    "    actual_fig = ax.bar(np.arange(n), avepp[actual], width)\n",
    "    ax.set_title(\"AvE Decile Plot\")\n",
    "    ax.set_xticks(np.arange(n) + width / 2)\n",
    "    ax.set_xticklabels(np.arange(n) + 1)\n",
    "    ax.legend((pred_fig[0], actual_fig[0]), (\"Pred\", \"Actual\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.concat(\n",
    "    [\n",
    "        X_test.reset_index(),\n",
    "        pd.DataFrame(gbm_pred, columns=[\"predicted\"]),\n",
    "        pd.DataFrame(y_test).reset_index(),\n",
    "    ], \n",
    "    axis=1\n",
    ").drop(\"index\", axis=1)\n",
    "\n",
    "plot_avepp(test_results, \"predicted\", \"charges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking RMSE for training and testing sets\n",
    "# An indication of overfitting would be a very low training RMSE with a high testing RMSE\n",
    "\n",
    "print(\"Overfitting Check\")\n",
    "print(\"Training RMSE: {}\".format(mean_squared_error(y_test, gbm_pred, squared=False)))\n",
    "print(\"Testing RMSE: {}\".format(mean_squared_error(y_train, gbm_model.predict(X_train), squared=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is SHAP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP stands for SHapley Additive exPlanations and uses a game theory approach (Shapley Values) applied to machine learning to \"fairly allocate contributions\" to the model features for a given output. The underlying process of getting SHAP values for a particular feature $f$ out of the set $F$ can be summarized as follows:\n",
    "\n",
    "- Get the [Power Set](https://en.wikipedia.org/wiki/Power_set) of $F$, which  contains $2^{F}$ combinations of features\n",
    "- Run the model for all possible combinations, treating features outside of the subset as missing\n",
    "- Record the marginal contributions to the model output for $f$\n",
    "- Calculate a weighted sum of $f$'s marginal contributions to get the SHAP value of feature $f$ for a given output. Or in other words, $f$'s expected contribution to the model output\n",
    "\n",
    "Just from looking at the steps mentioned above, we can infer that this approach would have 2 major issues to solve:\n",
    "1. Statistical models typically are not able to handle missing values\n",
    "2. $2^{F}$ is exponential complexity $O(2^{N})$, which is not feasible in most cases\n",
    "\n",
    "Thankfully, the good people working on the SHAP framework have built a very user-friendly API for us to define what \"missing\" means by creating background dataset that imputes the missing values while running our models. As for (2), SHAP values are generally approximated with sampling subsets of $2^{F}$. However, in the case of tree-based models and deep neural networks, there are elegant solutions implemented such that we can get exact solutions that run in polynomial $O(N^{2})$ time!\n",
    "\n",
    "While we will not delve into the details on how the SHAP algorithm handles these issues, the reader is encouraged to look at the various resources in the appendix to get a better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP package in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHAP python framework provides a variety of visualisations for model validation that can be found [here](https://shap.readthedocs.io/en/latest/api.html). However, for the purposes of this article, we will be focusing on the Waterfall, Force and Dependency plots to interpret our model predictions.\n",
    "\n",
    "We will also look at the results in the context of a particular observation with index=30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 30\n",
    "feature = \"bmi\"\n",
    "\n",
    "shap_df = pd.DataFrame(gbm_model.named_steps[\"preprocessor\"].transform(X_train), columns=rating_factors_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the LIME package, SHAP works with explainer objects to calculate the results, and provides us with 3 main explainer categories:\n",
    "\n",
    "- shap.TreeExplainer\n",
    "- shap.DeepExplainer\n",
    "- shap.KernelExplainer\n",
    "\n",
    "The first 2 are model specific algorithms, which makes use of the model architecture for optimizations to compute exact SHAP values as mentioned above. The KernelExplainer on the other hand, is a model agnostic algorithm uses sampling to approximate SHAP values. Since we have opted to use a GBM regressor in this article, we will be using the TreeExplainer object in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_explainer = shap.TreeExplainer(gbm_model.named_steps[\"model\"])\n",
    "gbm_shap_values = gbm_explainer(shap_df)\n",
    "\n",
    "# This line below is a quick workaround to get pass an assert condition in the SHAP \n",
    "# plots.waterfall source code. Can be ignored\n",
    "gbm_shap_values.base_values = gbm_shap_values.base_values[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waterfall Plots (Local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHAP waterfall plots aims to explain how individual claim predictions are derived.\n",
    "\n",
    "1. On the Y-axis, we have our encoded features, with the values observed for idx=30\n",
    "2. On the X-axis, we have the range of our response (claims costs) in dollars\n",
    "3. Note that $E[f(X)]=\\$13,189.258$ is the result from the null model, or the global average claims cost from our dataset\n",
    "4. Also note that $f(x)=\\$14,959.311$ is the model prediction for values observed in (1)\n",
    "\n",
    "We can see from the plot below that this policyholder’s expected claims cost is ~13% higher than the average, and both the gender and region did not contribute materially to this outcome. While the higher-than-average BMI did contribute to ~$1.3k more to the costs, this was mostly offset by the fact that she had no children.\n",
    "\n",
    "The 2 main drivers mostly offset each other as well, but the fact that she is aged outweighed the effect of being a non-smoker by ~$1.4k, which makes up the bulk of the net increase from the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shap.plots.waterfall(gbm_shap_values[idx], max_display=14, show=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Force plots (\"Global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The force plots in the SHAP package can output both local and \"global\" interpretation graphs. While it does not provide a global explanation in the form of an equation like in our GLMs, it does give us a model-level view of the results to work with. This is done by stacking and sorting all the SHAP values for all predictions into 1 plot as shown below. \n",
    "\n",
    "While both axes can be customized from the combo box, by default, the Y-axis shows the output value of the model, while the X-axis plots all the samples in the dataset sorted by similarity (I personally like sorting it by output value). By hovering over an area of the graph, we can get a quick summary of the significant rating factors that are driving the modelled costs up (in red) or down (in blue). \n",
    "\n",
    "Just at a high level we can observe that the model has put a lot of emphasis on the state of smoking and age, which is in line with high BMIs have an interaction effect with smoking, accounting for many of the higher claim predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Static image used for article in the event that init.js() does not run\n",
    "\n",
    "<img src=\"img/shap_waterfall.png\", width=450, height=450>\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(gbm_explainer.expected_value[0], gbm_shap_values.values, shap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP Dependency plots (\"Global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHAP dependency plot is a very simple graph that shows how the SHAP contributions differ for different values of the feature (BMI in this case). This is similar to a Partial Dependency Plot (PDP) which visualizes the marginal effect of a feature towards the model outcome by plotting out the average model predictions against different values of that feature. The SHAP dependency plots do not average the outcomes and show the variances on the y-axis. Here, we can clearly see an interaction effect between BMI values and the smoking state of the policyholder.\n",
    "\n",
    "We see that the pink data points (non-smokers) have a more gradual slope for BMI contributions in contrast to the blue points (smokers), where the SHAP contributions jump significantly at the BMI=~30 point, which is in line with what we could guess from the previous force plot output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(feature, gbm_shap_values.values, shap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP vs LIME?\n",
    "\n",
    "Now that we've seen some of the functionality available to us in the Python SHAP framework (available in R as well), it only makes sense to compare its advantages and disadvantages to another popular framework like LIME, which also utilizes the idea of explanation model for local interpretation using some form of linear approximation. Note that this list is non-exhaustive and only includes the most obvious/popular ones.\n",
    "\n",
    "**Advantages**:\n",
    "- SHAP provides a complete explanation between the global average and the model output for a particular explanation, whereas LIME's model may not, depending on the fit of the localized linear regression, this means that SHAP is more legally/professionally compliant than other methods.\n",
    "- SHAP values are fairly distributed among the features whereas LIME does not guarantee this.\n",
    "- SHAP has the backing of a long-standing and well understood economic theory. The underlying axioms and properties give SHAP a good foundation of why it should work, whereas LIME relies on the assumption of linearity locally.\n",
    "\n",
    "**Disadvantages**:\n",
    "- Only approximate SHAP values are feasible most of the time, the power set of models to compute exact solutions are very computationally expensive. Just imagine computing $2^{20}$ models on a small-sized dataset.\n",
    "- SHAP values can easily be misinterpreted. By removing the feature for a particular observation, we do not get an outcome of the prediction less the SHAP value of that feature.  This also means that SHAP values cannot make predictions for changes in the input whereas results from LIME allows statements like: \"_If this policyholder's BMI increased by 1, we can expect the modelled claims cost to increase by ~$500._\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afterward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data becomes increasingly available and insurance products continue to get more complex, the use of more robust models to handles these interactions will be inevitable for many prediction tasks across the whole insurance value chain, not just for claims modelling and fraud detection.\n",
    "\n",
    "Validation frameworks like SHAP and LIME seem to be a big step in the direction of model-agnostic-additive explanations. While article gives the reader a gentle and practical introduction to the idea and implementation behind SHAP, note that the theory and mathematics are a little more involved. If you are interested in deep diving into the details, there are a few links below to get you started.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)\n",
    "- [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)\n",
    "- [SHAP framework Github Repository](https://github.com/slundberg/shap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

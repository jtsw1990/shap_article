{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable ML: A peek into the black box through with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The insurance industry has always been more conservative when it comes to modelling, and with good reason. The financial and social impact of a wrongly predicted say, fraud detection model denying a policyholder’s entitlement to a claim is huge, compared to a wrongly predicted song recommendation pushed from your favourite music player’s machine learning algorithm. \n",
    "\n",
    "As actuaries doing technical modelling for insurance premiums, some common “workarounds” would be to stick with our favourite GLMs since it is a lot more transparent, or map/tag your GBM results to that of a GLM in some way, just to get some comfort and clarity regarding what the model is doing globally.\n",
    "\n",
    "In this article, we will introduce (at a high level) the underlying concept of SHAP, as well as work through the python implementation using a sample insurance claims dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this from your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python code shown this snippet can be run from your browser through this link.\n",
    "\n",
    "Note that some loading time is to be expected, particularly when performing gridsearch and cross-validation for the machine learning models. However, the binder does not require the reader to download the dataset, or any other dependencies to run the models. Furthermore, the reader is encouraged to play around with the code and look at how SHAP explains the different predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example uses [Python3](https://www.python.org/downloads/release/python-385/) and the main packages that we will be using are listed below:\n",
    "\n",
    "- [Shap](https://pypi.org/project/shap/) for model validation\n",
    "- [Matplotlib](https://pypi.org/project/matplotlib/) for visualisation as shap graphs uses it as a backend\n",
    "- [Pandas](https://pypi.org/project/pandas/) and [Numpy](https://pypi.org/project/numpy/) for general data manipulation\n",
    "- [Sci-kit learn's](https://pypi.org/project/scikit-learn/) pipeline framework\n",
    "\n",
    "Note that the sklearn pipeline is the main backbone of the process here out of convenience but any other framework would work just as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shap\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing, Preprocessing, Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in the article includes some policyholder information as follows: \n",
    "\n",
    "- **age**: Policyholder age (integer)\n",
    "- **sex**: Gender of the policyholder (female=0, male=1)\n",
    "- **bmi**: Body mass index (float)\n",
    "- **children**: Number of children/ dependents of policyholder (integer)\n",
    "- **smoker**: Smoking state of policyholder (non-smoker=0, smoker=1)\n",
    "- **region**: Residential area of the policyholder in the US (string)\n",
    "\n",
    "As well as a claims cost response column. The data can be downloaded from the github repository [here](https://github.com/sharmaroshan/Insurance-Claim-Prediction).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although all the usual steps in the modelling process are involved here, this article will mainly focus on using the SHAP package and interpreting the results. With that in mind, the rest of this section will not be covered in detail, but includes:\n",
    "- Importing the data\n",
    "- Splitting the dataset into training and testing sets\n",
    "- Creating a \"preprocesser\" step to one-hot-encode categorical features\n",
    "- Building a sklearn pipeline with the preprocessing and a GBM Regressor model\n",
    "- Performing gridsearch and cross-validation for the GBM model to get the \"best\" set of hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/sharmaroshan/Insurance-Claim-Prediction/master/insurance.csv\")\n",
    "\n",
    "rating_factors_col = list(df.columns[:-1])\n",
    "claims_col = df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = list(df[rating_factors_col].select_dtypes(include=[\"int64\", \"float64\"]).columns)\n",
    "cat_features = [col for col in rating_factors_col if col not in num_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df[rating_factors_col],\n",
    "            df[claims_col],\n",
    "            test_size=0.2,\n",
    "            random_state=123\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesser = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"numerical\", \"passthrough\", num_features),\n",
    "        (\"categorical\", OneHotEncoder(sparse=False, handle_unknown=\"ignore\"), cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_categories = preprocesser.fit(X_train).named_transformers_[\"categorical\"].categories_\n",
    "ohe_categories_concat = [f\"{col}__{val}\" for col, vals in zip(cat_features, ohe_categories) for val in vals]\n",
    "rating_factors_encoded = num_features + ohe_categories_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"model__learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"model__max_depth\": [2, 3, 4, 5],\n",
    "    \"model__max_features\": [2, 3, 5, 7],\n",
    "    \"model__min_samples_leaf\": [3, 4, 5],\n",
    "    \"model__min_samples_split\": [5, 8, 10, 12],\n",
    "    \"model__n_estimators\": [100, 200, 300, 500]\n",
    "}\n",
    "\n",
    "gbm_model = Pipeline([(\"preprocesser\", preprocesser), (\"model\", GradientBoostingRegressor())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling: Gradient Boosted Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(\n",
    "    gbm_model, \n",
    "    param_grid=param_grid, \n",
    "    n_jobs=-1, \n",
    "    cv=5, \n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model.set_params(**gs.best_params_)\n",
    "gbm_model.fit(X_train, y_train)\n",
    "gbm_pred = gbm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is SHAP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP stands for Shapley Additive Explanations and uses a game theory approach (Shapley Values) applied on machine learning to \"fairly allocate contributions\" to the model features for a given output. The underlying process of getting SHAP values for a particular feature $f$ out of the set $F$ can be summarized as follows:\n",
    "\n",
    "- Get the [Power Set](https://en.wikipedia.org/wiki/Power_set) of $F$, which  contains $2^{F}$ combinations of features\n",
    "- Run the model for all combinations in the set\n",
    "- Record the marginal contributions to the model output for $f$\n",
    "- Calculated a weighted sum of $f$'s marginal contributions to get the SHAP value of feature $f$ for a given output. Or in other words, $f$'s contribution to the model output\n",
    "\n",
    "For more details, there are various resources in the appendix for the reader to delve deeper into this concept, including the original white paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP package in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHAP python framework provides a variety of visualisations for model validation and can be found [here](https://shap.readthedocs.io/en/latest/api.html). However, for our purposes, we will only be concentrating on the Partial Dependency Plot (PDP) and the SHAP Waterfall Plot.\n",
    "\n",
    "We will also look at the results in the context of a particular observation with index=30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 30\n",
    "feature = \"bmi\"\n",
    "\n",
    "shap_df = pd.DataFrame(lr_model.named_steps[\"preprocesser\"].transform(X_train), columns=rating_factors_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the LIME package, SHAP works with explainer objects to calculate the results, and because we have opted to use a GBM regressor for this example, we will be using the TreeExplainer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_explainer = shap.TreeExplainer(gbm_model.named_steps[\"model\"])\n",
    "gbm_shap_values = gbm_explainer(shap_lr_df)\n",
    "\n",
    "# This line below is a quick workaround to get pass an assert condition in the SHAP \n",
    "# waterfall function. Can be ignored\n",
    "gbm_shap_values.base_values = gbm_shap_values.base_values[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waterfall Plots (Local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHAP waterfall plots aims to explain how individual claim predictions come about.\n",
    "\n",
    "1. On the Y-axis, we have our encoded features, with the values observed for idx=30\n",
    "2. On the X-axis, we have the range of our response (claims costs) in dollars\n",
    "3. Note that $E[f(X)]=\\$13,189.258$ is the result from the null model, or the global average claims cost from our dataset\n",
    "4. Also note that $f(x)=\\$14,959.311$ is the model prediction for values observed in (1)\n",
    "\n",
    "So, we can see from the plot below that this policyholder’s expected claims cost is ~13% higher than the average, and both the gender and region did not contribute materially to this outcome. While the higher-than-average BMI did contribute to ~$1.3k more to the costs, this was mostly offset by the fact that she had no children.\n",
    "\n",
    "The 2 main drivers mostly offset each other as well, but the fact that she is aged outweighed the effect of being a non-smoker by ~$1.4k, which makes up the bulk of the net increase from the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shap.plots.waterfall(gbm_shap_values[idx], max_display=14, show=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Force plots (\"Global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The force plots in the SHAP package can output both local and \"global\" interpretation graphs, but in this example, we have inputted the whole array of SHAP values and data points into the function, to get a model-level view of the results. \n",
    "\n",
    "While both axes can be customized from the combo box, by default, the Y-axis shows the output value of the model, while the X-axis plots all the samples in the dataset sorted by similarity (I personally like sorting it by output value). By hovering over an area of the graph, we can get a quick summary of the significant rating factors that are driving the modelled costs up (in red) or down (in blue). \n",
    "\n",
    "Just at a high level we can observe that the model has put a lot of emphasis on the state of smoking and age, which is in line with high BMIs have an interaction effect with smoking, accounting for many of the higher claim predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(gbm_explainer.expected_value[0], gbm_shap_values.values, shap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP Dependency plots (\"Global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHAP dependency plot is a very simple graph that shows how the SHAP contributions differ for different values of the feature (BMI in this case). This is like a PDP, except that PDPs show average effects while the SHAP dependency plots show the variance on the y-axis. Here, we can clearly see an interaction effect between BMI values and the smoking state of the policyholder.\n",
    "\n",
    "We see that the pink data points (non-smokers) have a more gradual slope for BMI contributions in contrast to the blue points (smokers), where the SHAP contributions jump significantly at the BMI=~30 point, which is in line with what we could guess from the previous force plot output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(feature, gbm_shap_values.values, shap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP vs LIME?\n",
    "\n",
    "Now that we've seen some of the functionality available to us in the Python SHAP framework (available in R as well), it only makes sense to compare its advantages and disadvantages to another popular framework like LIME, which also utilizes the idea of explanation model for local interpretation using some form of linear approximation. Note that this list is non-exhaustive and only includes the most obvious/popular ones.\n",
    "\n",
    "**Advantages**:\n",
    "- SHAP provides a complete explanation between the global average and the model output for a particular explanation, whereas LIME's model may not, depending on the fit of the localized linear regression, this means that SHAP is more legally/professionally compliant than other methods.\n",
    "- SHAP values are fairly distributed among the features whereas LIME does not guarantee this.\n",
    "- SHAP has the backing of a long-standing and well understood economic theory. The underlying axioms and properties give SHAP a good foundation of why it should work, whereas LIME relies on the assumption of linearity locally.\n",
    "\n",
    "**Disadvantages**:\n",
    "- Only approximate solutions are feasible most of the time, the power set of models to compute exact solutions are very computationally expensive. Just imagine computing $2^{20}$ GBM models on a small-sized dataset.\n",
    "\n",
    "- SHAP values can easily be misinterpreted. By removing the feature for a particular observation, we do not get an outcome of the prediction less the SHAP value of that feature.  This also means that SHAP values cannot make predictions for changes in the input whereas results from LIME allows statements like: \"_If this policyholder's BMI increased by 1, we can expect the modelled claims cost to increase by ~$500._\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afterward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data becomes increasingly available and insurance products continue to get more complex, the use of more robust models to handles these interactions will be inevitable for many prediction tasks across the whole insurance value chain, not just for claims modelling and fraud detection.\n",
    "\n",
    "Validation frameworks like SHAP and LIME seem to be a big step in the direction of model-agnostic-additive explanations. While article gives the reader a gentle and practical introduction to the idea and implementation behind SHAP, note that the theory and mathematics are a little more involved. If you are interested in deep diving into the details, there are a few links below to get you started.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)\n",
    "- [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)\n",
    "- [SHAP framework Github Repository](https://github.com/slundberg/shap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
